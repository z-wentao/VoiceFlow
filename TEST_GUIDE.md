# VoiceFlow 测试指南

## 🎯 测试目标

直观感受音频切片 + 并发处理的效果

## 📋 测试准备

### 1. 生成测试音频文件

使用 FFmpeg 生成不同时长的测试音频：

```bash
# 方法1: 生成 15 分钟的测试音频（会被切成 2 个片段）
ffmpeg -f lavfi -i "sine=frequency=1000:duration=900" -ar 44100 test_15min.mp3

# 方法2: 生成 30 分钟的测试音频（会被切成 3 个片段）
ffmpeg -f lavfi -i "sine=frequency=1000:duration=1800" -ar 44100 test_30min.mp3

# 方法3: 使用你已有的音频文件
# 直接上传任何 MP3/WAV/M4A 文件即可
```

### 2. 调整配置测试不同并发数

编辑 `config/config.yaml`：

```yaml
transcriber:
  segment_concurrency: 3    # 音频分片并发处理数（修改为 1/2/3/5 对比效果）
  segment_duration: 600     # 10分钟一片（可以改成 300 测试更多切片）
```

## 🚀 测试步骤

### 测试 1：观察切片过程

1. **启动服务器**
```bash
go run cmd/api/main.go
```

2. **上传 15 分钟音频**（浏览器访问 `http://localhost:8080`）

3. **观察终端日志输出**，你会看到：

```
📊 音频时长: 900.00 秒 (15.00 分钟)
✂️  音频将被切分为 2 个片段 (每片 600 秒)
  ✂️  正在切分片段 1/2: 0.00秒 -> 600.00秒 (时长: 600.00秒)
  ✂️  正在切分片段 2/2: 600.00秒 -> 900.00秒 (时长: 300.00秒)
✓ 音频已分片，共 2 个片段
🚀 启动 3 个并发 Worker 进行处理...
```

### 测试 2：对比不同并发数的处理时间

#### 2.1 单 Worker 处理（串行）

```yaml
# config/config.yaml
segment_concurrency: 1
```

上传 30 分钟音频，记录总耗时

#### 2.2 三分片并发处理

```yaml
# config/config.yaml
segment_concurrency: 3
```

上传同样的 30 分钟音频，对比耗时差异

**预期效果**：
- 并发数为 1：处理 3 个片段需要 `T1 + T2 + T3` 时间（串行）
- 并发数为 3：处理 3 个片段只需要 `max(T1, T2, T3)` 时间（并行）

### 测试 3：观察并发处理日志

上传音频后，你会看到类似这样的日志：

```
🔄 [分片处理器-0] 正在处理片段 #0 (0.0s - 600.0s)
🔄 [分片处理器-1] 正在处理片段 #1 (600.0s - 1200.0s)
🔄 [分片处理器-2] 正在处理片段 #2 (1200.0s - 1800.0s)
✅ 片段 #0 转换完成 | 进度: 1/3 (33.3%) | 文本长度: 1234 字符
✅ 片段 #1 转换完成 | 进度: 2/3 (66.7%) | 文本长度: 1456 字符
✅ 片段 #2 转换完成 | 进度: 3/3 (100.0%) | 文本长度: 890 字符
🎉 任务 xxx 完成！
⏱️  总耗时: 45.32 秒 (0.76 分钟)
```

**关键点**：
- 观察 3 个分片处理器是否同时开始处理（并发）
- 观察总耗时是否显著小于片段数 × 单片段处理时间

## 📊 测试场景对比

| 场景 | 音频时长 | 切片数 | 分片并发数 | 预期效果 |
|------|---------|--------|----------|---------|
| 场景1 | 8分钟 | 1 | 3 | 无需切片，直接处理 |
| 场景2 | 15分钟 | 2 | 1 | 串行处理，耗时 = T1 + T2 |
| 场景3 | 15分钟 | 2 | 2 | 并发处理，耗时 ≈ max(T1, T2) |
| 场景4 | 30分钟 | 3 | 3 | 理想并发，3片段同时处理 |
| 场景5 | 60分钟 | 6 | 3 | 分片处理器复用，分批处理 |

## 🔍 调试技巧

### 1. 修改切片时长（更容易观察）

```yaml
# 改成 5 分钟一片，更容易生成多个片段
segment_duration: 300
```

### 2. 查看实时日志

```bash
# 启动服务器时，日志会实时显示
go run cmd/api/main.go
```

### 3. 使用 API 测试（跳过前端）

```bash
# 上传文件
curl -X POST http://localhost:8080/api/upload \
  -F "audio=@test_15min.mp3"

# 查询任务状态
curl http://localhost:8080/api/jobs/{job_id}
```

## 📈 性能测试

### 生成不同大小的测试文件

```bash
# 生成 50MB 测试文件（约20分钟音频）
ffmpeg -f lavfi -i "sine=frequency=1000:duration=1200" \
  -ar 44100 -b:a 320k test_50mb.mp3

# 生成 100MB 测试文件（约40分钟音频）
ffmpeg -f lavfi -i "sine=frequency=1000:duration=2400" \
  -ar 44100 -b:a 320k test_100mb.mp3

# 生成 200MB 测试文件（约80分钟音频）
ffmpeg -f lavfi -i "sine=frequency=1000:duration=4800" \
  -ar 44100 -b:a 320k test_200mb.mp3
```

### 压力测试（多任务并发）

打开多个浏览器标签，同时上传多个文件，观察：
- 任务队列是否正常工作
- 多个任务是否能并行处理
- 系统资源使用情况（CPU/内存）

## 🎯 预期观察结果

### ✅ 成功标志

1. **日志清晰**：能看到切片数量、分片处理器启动、处理进度
2. **并发效果明显**：3个分片处理器处理3个片段，几乎同时完成
3. **性能提升**：并发处理比串行快 2-3 倍
4. **大文件支持**：能上传并处理 300MB 以内的文件

### ⚠️ 可能的问题

1. **Whisper API 限流**：如果并发过高可能触发限流
   - 解决：减少 segment_concurrency 或增加重试间隔

2. **FFmpeg 未安装**：切片失败
   - 解决：`brew install ffmpeg`（macOS）

3. **磁盘空间不足**：临时片段文件占用空间
   - 解决：处理完自动清理，检查 uploads/segments 目录

## 💡 面试展示技巧

运行测试时，向面试官展示：

1. **打开终端** → 启动服务器
2. **打开浏览器** → 上传 30 分钟音频
3. **指向终端日志** → "你看，这里音频被切成 3 个片段"
4. **观察并发日志** → "3 个分片处理器同时开始处理不同片段"
5. **查看完成日志** → "并发处理只用了 X 秒，串行需要 3X 秒"

**话术**：
> "这个项目的核心亮点是音频分片 + Goroutine Pool 并发处理。比如这个 30 分钟的音频，系统会自动切成 3 个 10 分钟的片段，然后用 3 个分片处理器并发调用 Whisper API。理想情况下，处理时间可以缩短到原来的 1/3。"
